# ETL Pipeline with Airflow

This project demonstrates a simple ETL pipeline using Apache Airflow. It extracts data from an API, transforms it using pandas, and loads it into a PostgreSQL database.

## ğŸ“¦ Tech Stack
- Python
- Apache Airflow
- PostgreSQL
- Docker (for local setup)

## ğŸ” Pipeline Steps
1. **Extract** â€“ Pull data from a sample API (e.g., dummy JSON placeholder)
2. **Transform** â€“ Clean and filter data using pandas
3. **Load** â€“ Insert cleaned data into PostgreSQL

## ğŸš€ Getting Started

```bash
# Clone the repo
git clone https://github.com/atabbas13/simple-etl-airflow-pipeline.git
cd simple-etl-airflow-pipeline

# Run using Docker
docker-compose up
```
---

The rest is coming soon
